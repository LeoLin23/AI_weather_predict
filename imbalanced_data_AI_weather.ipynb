{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imbalanced_data_AI_weather.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM7hDSNClfoK"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8o1FHzD-_y_"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3iZVjziKHmX"
      },
      "source": [
        "## Data processing and exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sA9WOcmzH2D"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR_SnbMArXr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bfd902-10a4-49bd-c4f2-0a9bd3879b39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fgdQgmwUFuj"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/AI_weather')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "W7uSbPOSHxbF",
        "outputId": "cb6a0071-7730-4021-c9e1-0dadbb973c6b"
      },
      "source": [
        "weather = pd.read_csv(\"train.csv\")\n",
        "weather.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.29</td>\n",
              "      <td>9.5</td>\n",
              "      <td>0.042</td>\n",
              "      <td>56.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.99586</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0.51</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6.2</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.24</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0.032</td>\n",
              "      <td>19.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.98934</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.26</td>\n",
              "      <td>13.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.047</td>\n",
              "      <td>30.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.99310</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.48</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.19</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0.040</td>\n",
              "      <td>48.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.99579</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.040</td>\n",
              "      <td>21.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.99230</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.38</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   X1    X2    X3   X4     X5  ...     X7       X8    X9   X10   X11  Y\n",
              "0           0  6.8  0.24  0.29  9.5  0.042  ...  157.0  0.99586  3.11  0.51  10.1  3\n",
              "1           1  6.2  0.37  0.24  6.1  0.032  ...   86.0  0.98934  3.04  0.26  13.4  5\n",
              "2           2  6.0  0.40  0.30  1.6  0.047  ...  117.0  0.99310  3.17  0.48  10.1  3\n",
              "3           3  7.1  0.28  0.19  7.8  0.040  ...  184.0  0.99579  3.16  0.50   9.4  2\n",
              "4           4  7.0  0.35  0.24  1.9  0.040  ...  144.0  0.99230  3.35  0.38  11.0  2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qox6ryyzwdr"
      },
      "source": [
        "### Clean, split and normalize the data\n",
        "\n",
        "The raw data has a few issues. First the `Time` and `Amount` columns are too variable to use directly. Drop the `Time` column (since it's not clear what it means) and take the log of the `Amount` column to reduce its range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef42jTuxEjnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b5b66ba4-2c94-48e5-a956-272a82fe5639"
      },
      "source": [
        "answer_Y=weather.Y\n",
        "drop_list = ['Unnamed: 0']\n",
        "cleaned_df = weather.drop(drop_list,axis = 1 )\n",
        "cleaned_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.29</td>\n",
              "      <td>9.5</td>\n",
              "      <td>0.042</td>\n",
              "      <td>56.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.99586</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0.51</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.24</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0.032</td>\n",
              "      <td>19.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.98934</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.26</td>\n",
              "      <td>13.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.047</td>\n",
              "      <td>30.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.99310</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.48</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.19</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0.040</td>\n",
              "      <td>48.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>0.99579</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.040</td>\n",
              "      <td>21.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.99230</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.38</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    X1    X2    X3   X4     X5    X6     X7       X8    X9   X10   X11  Y\n",
              "0  6.8  0.24  0.29  9.5  0.042  56.0  157.0  0.99586  3.11  0.51  10.1  3\n",
              "1  6.2  0.37  0.24  6.1  0.032  19.0   86.0  0.98934  3.04  0.26  13.4  5\n",
              "2  6.0  0.40  0.30  1.6  0.047  30.0  117.0  0.99310  3.17  0.48  10.1  3\n",
              "3  7.1  0.28  0.19  7.8  0.040  48.0  184.0  0.99579  3.16  0.50   9.4  2\n",
              "4  7.0  0.35  0.24  1.9  0.040  21.0  144.0  0.99230  3.35  0.38  11.0  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNgdQFFFQ6u"
      },
      "source": [
        "Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) is a significant concern from the lack of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "--xyjztYIPYD",
        "outputId": "e792c0bb-5a7a-4294-ab0c-afb5b6c431d3"
      },
      "source": [
        "ax = sns.countplot(answer_Y,label=\"Count\")\n",
        "print(answer_Y.value_counts())\n",
        "l1, l2, l3, l4, l5 = answer_Y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3    1651\n",
            "2    1096\n",
            "4     652\n",
            "5     135\n",
            "1     120\n",
            "Name: Y, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0w1eR0yK6uo"
      },
      "source": [
        "Balance the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhy4zjxSK-vL",
        "outputId": "07f9661b-d9d0-4f20-ddd2-1f8d35d56197"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\r\n",
        "\r\n",
        "smote = SMOTE(random_state=500)\r\n",
        "X_smote, Y_smote = smote.fit_sample(cleaned_df,answer_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RtCgokSMp58",
        "outputId": "e06471c8-f31e-4134-ae8b-3f018b27099a"
      },
      "source": [
        "X_smote"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.8       ,  0.24      ,  0.29      , ...,  0.51      ,\n",
              "        10.1       ,  3.        ],\n",
              "       [ 6.2       ,  0.37      ,  0.24      , ...,  0.26      ,\n",
              "        13.4       ,  5.        ],\n",
              "       [ 6.        ,  0.4       ,  0.3       , ...,  0.48      ,\n",
              "        10.1       ,  3.        ],\n",
              "       ...,\n",
              "       [ 6.7931489 ,  0.27506808,  0.31931489, ...,  0.6831489 ,\n",
              "        12.26438297,  5.        ],\n",
              "       [ 6.77429367,  0.22937286,  0.34365725, ...,  0.52782677,\n",
              "        11.71943494,  5.        ],\n",
              "       [ 6.82674825,  0.22      ,  0.30331294, ...,  0.38331294,\n",
              "        11.98024474,  5.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfxhKg7Yr1-b"
      },
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Y'))\n",
        "bool_train_labels = train_labels != 0\n",
        "val_labels = np.array(val_df.pop('Y'))\n",
        "test_labels = np.array(test_df.pop('Y'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_Z_kBmr7Oh"
      },
      "source": [
        "Normalize the input features using the sklearn StandardScaler.\n",
        "This will set the mean to 0 and standard deviation to 1.\n",
        "\n",
        "Note: The `StandardScaler` is only fit using the `train_features` to be sure the model is not peeking at the validation or test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO-qEUmJ5JQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f435e432-6413-4eea-81cc-064756ec60a2"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "val_features\n",
        "train_features = np.clip(train_features, -5, 5)\n",
        "val_features = np.clip(val_features, -5, 5)\n",
        "test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "train_labels = pd.get_dummies(train_labels,sparse=True)\n",
        "test_labels = pd.get_dummies(test_labels,sparse=True)\n",
        "val_labels = pd.get_dummies(val_labels,sparse=True)\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Validation labels shape:', val_labels.shape)\n",
        "print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Validation features shape:', val_features.shape)\n",
        "print('Test features shape:', test_features.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.39840513, -0.47069173, -0.6917253 , ..., -0.26983827,\n",
              "        -0.58859532, -1.09203845],\n",
              "       [-1.47746818, -1.53944641, -0.60848613, ...,  1.1152657 ,\n",
              "        -0.23861163, -1.09203845],\n",
              "       [-0.39840513, -0.17921318,  3.3869938 , ..., -0.07196628,\n",
              "         0.46135574, -0.85089533],\n",
              "       ...,\n",
              "       [ 1.16024149,  0.11226537,  0.22390552, ...,  0.45569238,\n",
              "        -1.02607492,  0.51558238],\n",
              "       [-0.39840513,  0.01510585, -0.02581197, ...,  0.19186305,\n",
              "         0.19886797, -0.69013324],\n",
              "       [-0.63819692, -0.47069173, -0.27552947, ...,  0.58760704,\n",
              "        -0.76358716,  0.99786864]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "uCI5nSyLYXRL",
        "outputId": "3b85b23c-b366-4173-88a8-eae3abdd5dba"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2333</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2334</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2335</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2336</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2337</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2338 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1  2  3  4  5\n",
              "0     0  1  0  0  0\n",
              "1     0  0  1  0  0\n",
              "2     0  0  1  0  0\n",
              "3     0  0  1  0  0\n",
              "4     0  0  1  0  0\n",
              "...  .. .. .. .. ..\n",
              "2333  0  0  1  0  0\n",
              "2334  0  0  1  0  0\n",
              "2335  0  0  1  0  0\n",
              "2336  1  0  0  0  0\n",
              "2337  0  0  1  0  0\n",
              "\n",
              "[2338 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 455
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF2nNfWKJ33w"
      },
      "source": [
        "Caution: If you want to deploy a model, it's critical that you preserve the preprocessing calculations. The easiest way to implement them as layers, and attach them to your model before export.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7m9nqDC3W6"
      },
      "source": [
        "### Look at the data distribution\n",
        "\n",
        "Next compare the distributions of the positive and negative examples over a few features. Good questions to ask yourself at this point are:\n",
        "\n",
        "* Do these distributions make sense? \n",
        "    * Yes. You've normalized the input and these are mostly concentrated in the `+/- 2` range.\n",
        "* Can you see the difference between the distributions?\n",
        "    * Yes the positive examples contain a much higher rate of extreme values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFK1u4JX16D8"
      },
      "source": [
        "## Define the model and metrics\n",
        "\n",
        "Define a function that creates a simple neural network with a densly connected hidden layer, a [dropout](https://developers.google.com/machine-learning/glossary/#dropout_regularization) layer to reduce overfitting, and an output sigmoid layer that returns the probability of a transaction being fraudulent: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JQDzUqT3UYG"
      },
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def make_model(metrics=METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, activation='relu',input_dim=11)) \n",
        "  for i in range(5):\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "  model.add(Dense(5, activation='softmax',bias_initializer=output_bias))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYdhSAoaF_TK"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDbltVPg2m2q"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "Now create and train your model using the function that was defined earlier. Notice that the model is fit using a larger than default batch size of 2048, this is important to ensure that each batch has a decent chance of containing a few positive samples. If the batch size was too small, they would likely have no fraudulent transactions to learn from.\n",
        "\n",
        "\n",
        "Note: this model will not handle the class imbalance well. You will improve it later in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouUkwPcGQsy3"
      },
      "source": [
        "EPOCHS = 150\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xlR_dekzw7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560abde0-1ef6-438c-f88c-79aea3dbd5e7"
      },
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_360 (Dense)            (None, 256)               3072      \n",
            "_________________________________________________________________\n",
            "dense_361 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_240 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_362 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_241 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_363 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_242 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_364 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_243 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_365 (Dense)            (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_244 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_366 (Dense)            (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 102,661\n",
            "Trainable params: 102,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7ND3_SqckO"
      },
      "source": [
        "Test run the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LopSd-yQqO3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b24db39-7e7b-45aa-b427-9886b62db156"
      },
      "source": [
        "model.predict(train_features[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f43febb5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09841722, 0.27535298, 0.22441506, 0.1586069 , 0.24320789],\n",
              "       [0.09047152, 0.27003133, 0.22927138, 0.17632222, 0.23390345],\n",
              "       [0.10096019, 0.2888353 , 0.22647311, 0.14524929, 0.23848213],\n",
              "       [0.11133619, 0.27283776, 0.22468144, 0.15198538, 0.23915924],\n",
              "       [0.10397301, 0.27394155, 0.2231561 , 0.16304277, 0.23588654],\n",
              "       [0.10896584, 0.26918647, 0.22825865, 0.1538913 , 0.23969778],\n",
              "       [0.10742947, 0.27572557, 0.23085526, 0.14863572, 0.23735404],\n",
              "       [0.109071  , 0.2631505 , 0.23708364, 0.15034708, 0.24034776],\n",
              "       [0.10586432, 0.27953148, 0.237452  , 0.14973348, 0.22741878],\n",
              "       [0.10579574, 0.26528773, 0.2304252 , 0.15700221, 0.24148917]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKIgWqHms_03"
      },
      "source": [
        "### Optional: Set the correct initial bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk_3Ry6EoYDq"
      },
      "source": [
        "These initial guesses are not great. You know the dataset is imbalanced. Set the output layer's bias to reflect that (See: [A Recipe for Training Neural Networks: \"init well\"](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines)). This can help with initial convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbfWDuVpo6k"
      },
      "source": [
        "With the default bias initialization the loss should be about `math.log(2) = 0.69314` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-oPqh3SoGXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a56235-27a8-40cd-cc38-7876a2fe5fdd"
      },
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.5061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50oyu1uss0i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694e073b-57af-40fc-a345-10805a7b5a67"
      },
      "source": [
        "model = make_model(output_bias=None)\n",
        "model.predict(train_features[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f43fe90bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1191036 , 0.34429178, 0.07502451, 0.1428804 , 0.31869972],\n",
              "       [0.12415014, 0.34093225, 0.07640043, 0.1363984 , 0.32211876],\n",
              "       [0.10867872, 0.34481668, 0.07750338, 0.13979307, 0.32920805],\n",
              "       [0.10709494, 0.34824434, 0.08089738, 0.13597214, 0.32779115],\n",
              "       [0.11542398, 0.3531    , 0.07781123, 0.13685587, 0.31680894],\n",
              "       [0.11214091, 0.3460452 , 0.07852865, 0.13658549, 0.32669973],\n",
              "       [0.10645702, 0.35744396, 0.08037866, 0.13255152, 0.32316878],\n",
              "       [0.12044375, 0.33335292, 0.07723605, 0.12957709, 0.33939025],\n",
              "       [0.11170427, 0.33543462, 0.08219475, 0.13819209, 0.33247426],\n",
              "       [0.10702825, 0.3449577 , 0.08138718, 0.13757068, 0.3290562 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xqFYb2KqRHQ"
      },
      "source": [
        "With this initialization the initial loss should be approximately:\n",
        "\n",
        "$$-p_0log(p_0)-(1-p_0)log(1-p_0) = 0.01317$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVDqCWXDqHSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b51ab1-3074-41d1-a26b-02236a088d03"
      },
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.9272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDC8hvNr9yw"
      },
      "source": [
        "This initial loss is about 50 times less than if would have been with naive initialization.\n",
        "\n",
        "This way the model doesn't need to spend the first few epochs just learning that positive examples are unlikely. This also makes it easier to read plots of the loss during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJj9ixKVBMT"
      },
      "source": [
        "### Checkpoint the initial weights\n",
        "\n",
        "To make the various training runs more comparable, keep this initial model's weights in a checkpoint file, and load them into each model before training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tSUm4yAVIif"
      },
      "source": [
        "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVXiLyqyZ8AX"
      },
      "source": [
        "### Confirm that the bias fix helps\n",
        "\n",
        "Before moving on, confirm quick that the careful bias initialization actually helped.\n",
        "\n",
        "Train the model for 20 epochs, with and without this careful initialization, and compare the losses: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8DsLXHQaSql"
      },
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "careful_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsA_7SEntRaV"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZKAc8NCDnoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d96f9fd-277c-41ce-8e27-53244eedb663"
      },
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "baseline_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "234/234 [==============================] - 2s 10ms/step - loss: 1.4282 - tp: 517.0000 - fp: 517.0000 - tn: 11175.0000 - fn: 2406.0000 - accuracy: 0.8000 - precision: 0.5000 - recall: 0.1769 - auc: 0.7599 - val_loss: 1.3472 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 2340.0000 - val_fn: 585.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7595\n",
            "Epoch 2/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.2925 - tp: 354.0000 - fp: 394.0000 - tn: 8958.0000 - fn: 1984.0000 - accuracy: 0.7966 - precision: 0.4733 - recall: 0.1514 - auc: 0.7806 - val_loss: 1.2589 - val_tp: 26.0000 - val_fp: 16.0000 - val_tn: 2324.0000 - val_fn: 559.0000 - val_accuracy: 0.8034 - val_precision: 0.6190 - val_recall: 0.0444 - val_auc: 0.7967\n",
            "Epoch 3/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.2391 - tp: 417.0000 - fp: 455.0000 - tn: 8897.0000 - fn: 1921.0000 - accuracy: 0.7967 - precision: 0.4782 - recall: 0.1784 - auc: 0.7990 - val_loss: 1.1462 - val_tp: 101.0000 - val_fp: 76.0000 - val_tn: 2264.0000 - val_fn: 484.0000 - val_accuracy: 0.8085 - val_precision: 0.5706 - val_recall: 0.1726 - val_auc: 0.8288\n",
            "Epoch 4/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.1663 - tp: 585.0000 - fp: 522.0000 - tn: 8830.0000 - fn: 1753.0000 - accuracy: 0.8054 - precision: 0.5285 - recall: 0.2502 - auc: 0.8206 - val_loss: 1.1253 - val_tp: 127.0000 - val_fp: 99.0000 - val_tn: 2241.0000 - val_fn: 458.0000 - val_accuracy: 0.8096 - val_precision: 0.5619 - val_recall: 0.2171 - val_auc: 0.8333\n",
            "Epoch 5/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.1440 - tp: 673.0000 - fp: 547.0000 - tn: 8805.0000 - fn: 1665.0000 - accuracy: 0.8108 - precision: 0.5516 - recall: 0.2879 - auc: 0.8269 - val_loss: 1.0995 - val_tp: 135.0000 - val_fp: 100.0000 - val_tn: 2240.0000 - val_fn: 450.0000 - val_accuracy: 0.8120 - val_precision: 0.5745 - val_recall: 0.2308 - val_auc: 0.8407\n",
            "Epoch 6/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.1359 - tp: 645.0000 - fp: 558.0000 - tn: 8794.0000 - fn: 1693.0000 - accuracy: 0.8074 - precision: 0.5362 - recall: 0.2759 - auc: 0.8276 - val_loss: 1.1081 - val_tp: 167.0000 - val_fp: 131.0000 - val_tn: 2209.0000 - val_fn: 418.0000 - val_accuracy: 0.8123 - val_precision: 0.5604 - val_recall: 0.2855 - val_auc: 0.8342\n",
            "Epoch 7/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.1186 - tp: 702.0000 - fp: 578.0000 - tn: 8774.0000 - fn: 1636.0000 - accuracy: 0.8106 - precision: 0.5484 - recall: 0.3003 - auc: 0.8338 - val_loss: 1.0776 - val_tp: 201.0000 - val_fp: 142.0000 - val_tn: 2198.0000 - val_fn: 384.0000 - val_accuracy: 0.8202 - val_precision: 0.5860 - val_recall: 0.3436 - val_auc: 0.8482\n",
            "Epoch 8/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0788 - tp: 800.0000 - fp: 618.0000 - tn: 8734.0000 - fn: 1538.0000 - accuracy: 0.8156 - precision: 0.5642 - recall: 0.3422 - auc: 0.8459 - val_loss: 1.0849 - val_tp: 209.0000 - val_fp: 157.0000 - val_tn: 2183.0000 - val_fn: 376.0000 - val_accuracy: 0.8178 - val_precision: 0.5710 - val_recall: 0.3573 - val_auc: 0.8437\n",
            "Epoch 9/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0789 - tp: 812.0000 - fp: 593.0000 - tn: 8759.0000 - fn: 1526.0000 - accuracy: 0.8187 - precision: 0.5779 - recall: 0.3473 - auc: 0.8460 - val_loss: 1.0598 - val_tp: 229.0000 - val_fp: 163.0000 - val_tn: 2177.0000 - val_fn: 356.0000 - val_accuracy: 0.8226 - val_precision: 0.5842 - val_recall: 0.3915 - val_auc: 0.8516\n",
            "Epoch 10/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0706 - tp: 858.0000 - fp: 614.0000 - tn: 8738.0000 - fn: 1480.0000 - accuracy: 0.8209 - precision: 0.5829 - recall: 0.3670 - auc: 0.8490 - val_loss: 1.0636 - val_tp: 234.0000 - val_fp: 171.0000 - val_tn: 2169.0000 - val_fn: 351.0000 - val_accuracy: 0.8215 - val_precision: 0.5778 - val_recall: 0.4000 - val_auc: 0.8502\n",
            "Epoch 11/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0613 - tp: 919.0000 - fp: 623.0000 - tn: 8729.0000 - fn: 1419.0000 - accuracy: 0.8253 - precision: 0.5960 - recall: 0.3931 - auc: 0.8524 - val_loss: 1.0520 - val_tp: 235.0000 - val_fp: 159.0000 - val_tn: 2181.0000 - val_fn: 350.0000 - val_accuracy: 0.8260 - val_precision: 0.5964 - val_recall: 0.4017 - val_auc: 0.8554\n",
            "Epoch 12/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0480 - tp: 868.0000 - fp: 592.0000 - tn: 8760.0000 - fn: 1470.0000 - accuracy: 0.8236 - precision: 0.5945 - recall: 0.3713 - auc: 0.8550 - val_loss: 1.0215 - val_tp: 253.0000 - val_fp: 167.0000 - val_tn: 2173.0000 - val_fn: 332.0000 - val_accuracy: 0.8294 - val_precision: 0.6024 - val_recall: 0.4325 - val_auc: 0.8623\n",
            "Epoch 13/150\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 1.0587 - tp: 886.0000 - fp: 656.0000 - tn: 8696.0000 - fn: 1452.0000 - accuracy: 0.8197 - precision: 0.5746 - recall: 0.3790 - auc: 0.8516 - val_loss: 1.0503 - val_tp: 215.0000 - val_fp: 137.0000 - val_tn: 2203.0000 - val_fn: 370.0000 - val_accuracy: 0.8267 - val_precision: 0.6108 - val_recall: 0.3675 - val_auc: 0.8564\n",
            "Epoch 14/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0351 - tp: 928.0000 - fp: 608.0000 - tn: 8744.0000 - fn: 1410.0000 - accuracy: 0.8274 - precision: 0.6042 - recall: 0.3969 - auc: 0.8588 - val_loss: 1.0397 - val_tp: 224.0000 - val_fp: 163.0000 - val_tn: 2177.0000 - val_fn: 361.0000 - val_accuracy: 0.8209 - val_precision: 0.5788 - val_recall: 0.3829 - val_auc: 0.8567\n",
            "Epoch 15/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0260 - tp: 938.0000 - fp: 632.0000 - tn: 8720.0000 - fn: 1400.0000 - accuracy: 0.8262 - precision: 0.5975 - recall: 0.4012 - auc: 0.8605 - val_loss: 1.0642 - val_tp: 239.0000 - val_fp: 191.0000 - val_tn: 2149.0000 - val_fn: 346.0000 - val_accuracy: 0.8164 - val_precision: 0.5558 - val_recall: 0.4085 - val_auc: 0.8495\n",
            "Epoch 16/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0324 - tp: 940.0000 - fp: 686.0000 - tn: 8666.0000 - fn: 1398.0000 - accuracy: 0.8217 - precision: 0.5781 - recall: 0.4021 - auc: 0.8586 - val_loss: 1.0370 - val_tp: 204.0000 - val_fp: 143.0000 - val_tn: 2197.0000 - val_fn: 381.0000 - val_accuracy: 0.8209 - val_precision: 0.5879 - val_recall: 0.3487 - val_auc: 0.8572\n",
            "Epoch 17/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0285 - tp: 1005.0000 - fp: 616.0000 - tn: 8736.0000 - fn: 1333.0000 - accuracy: 0.8333 - precision: 0.6200 - recall: 0.4299 - auc: 0.8613 - val_loss: 1.0262 - val_tp: 233.0000 - val_fp: 169.0000 - val_tn: 2171.0000 - val_fn: 352.0000 - val_accuracy: 0.8219 - val_precision: 0.5796 - val_recall: 0.3983 - val_auc: 0.8606\n",
            "Epoch 18/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0028 - tp: 1071.0000 - fp: 618.0000 - tn: 8734.0000 - fn: 1267.0000 - accuracy: 0.8388 - precision: 0.6341 - recall: 0.4581 - auc: 0.8687 - val_loss: 1.0175 - val_tp: 246.0000 - val_fp: 177.0000 - val_tn: 2163.0000 - val_fn: 339.0000 - val_accuracy: 0.8236 - val_precision: 0.5816 - val_recall: 0.4205 - val_auc: 0.8631\n",
            "Epoch 19/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0172 - tp: 1018.0000 - fp: 658.0000 - tn: 8694.0000 - fn: 1320.0000 - accuracy: 0.8308 - precision: 0.6074 - recall: 0.4354 - auc: 0.8634 - val_loss: 1.0153 - val_tp: 261.0000 - val_fp: 172.0000 - val_tn: 2168.0000 - val_fn: 324.0000 - val_accuracy: 0.8304 - val_precision: 0.6028 - val_recall: 0.4462 - val_auc: 0.8641\n",
            "Epoch 20/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0099 - tp: 1030.0000 - fp: 655.0000 - tn: 8697.0000 - fn: 1308.0000 - accuracy: 0.8321 - precision: 0.6113 - recall: 0.4405 - auc: 0.8669 - val_loss: 1.0394 - val_tp: 228.0000 - val_fp: 172.0000 - val_tn: 2168.0000 - val_fn: 357.0000 - val_accuracy: 0.8191 - val_precision: 0.5700 - val_recall: 0.3897 - val_auc: 0.8556\n",
            "Epoch 21/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9979 - tp: 1076.0000 - fp: 657.0000 - tn: 8695.0000 - fn: 1262.0000 - accuracy: 0.8358 - precision: 0.6209 - recall: 0.4602 - auc: 0.8691 - val_loss: 1.0349 - val_tp: 267.0000 - val_fp: 179.0000 - val_tn: 2161.0000 - val_fn: 318.0000 - val_accuracy: 0.8301 - val_precision: 0.5987 - val_recall: 0.4564 - val_auc: 0.8592\n",
            "Epoch 22/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9856 - tp: 1053.0000 - fp: 639.0000 - tn: 8713.0000 - fn: 1285.0000 - accuracy: 0.8354 - precision: 0.6223 - recall: 0.4504 - auc: 0.8717 - val_loss: 1.0252 - val_tp: 253.0000 - val_fp: 165.0000 - val_tn: 2175.0000 - val_fn: 332.0000 - val_accuracy: 0.8301 - val_precision: 0.6053 - val_recall: 0.4325 - val_auc: 0.8615\n",
            "Epoch 23/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0033 - tp: 1050.0000 - fp: 633.0000 - tn: 8719.0000 - fn: 1288.0000 - accuracy: 0.8357 - precision: 0.6239 - recall: 0.4491 - auc: 0.8684 - val_loss: 1.0152 - val_tp: 255.0000 - val_fp: 159.0000 - val_tn: 2181.0000 - val_fn: 330.0000 - val_accuracy: 0.8328 - val_precision: 0.6159 - val_recall: 0.4359 - val_auc: 0.8640\n",
            "Epoch 24/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9958 - tp: 1042.0000 - fp: 636.0000 - tn: 8716.0000 - fn: 1296.0000 - accuracy: 0.8347 - precision: 0.6210 - recall: 0.4457 - auc: 0.8697 - val_loss: 1.0169 - val_tp: 258.0000 - val_fp: 171.0000 - val_tn: 2169.0000 - val_fn: 327.0000 - val_accuracy: 0.8297 - val_precision: 0.6014 - val_recall: 0.4410 - val_auc: 0.8618\n",
            "Epoch 25/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9927 - tp: 1042.0000 - fp: 633.0000 - tn: 8719.0000 - fn: 1296.0000 - accuracy: 0.8350 - precision: 0.6221 - recall: 0.4457 - auc: 0.8713 - val_loss: 1.0266 - val_tp: 234.0000 - val_fp: 173.0000 - val_tn: 2167.0000 - val_fn: 351.0000 - val_accuracy: 0.8209 - val_precision: 0.5749 - val_recall: 0.4000 - val_auc: 0.8587\n",
            "Epoch 26/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9961 - tp: 1031.0000 - fp: 604.0000 - tn: 8748.0000 - fn: 1307.0000 - accuracy: 0.8365 - precision: 0.6306 - recall: 0.4410 - auc: 0.8702 - val_loss: 1.0185 - val_tp: 269.0000 - val_fp: 178.0000 - val_tn: 2162.0000 - val_fn: 316.0000 - val_accuracy: 0.8311 - val_precision: 0.6018 - val_recall: 0.4598 - val_auc: 0.8626\n",
            "Epoch 27/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9775 - tp: 1105.0000 - fp: 668.0000 - tn: 8684.0000 - fn: 1233.0000 - accuracy: 0.8374 - precision: 0.6232 - recall: 0.4726 - auc: 0.8738 - val_loss: 1.0260 - val_tp: 275.0000 - val_fp: 192.0000 - val_tn: 2148.0000 - val_fn: 310.0000 - val_accuracy: 0.8284 - val_precision: 0.5889 - val_recall: 0.4701 - val_auc: 0.8618\n",
            "Epoch 28/150\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9644 - tp: 1116.0000 - fp: 626.0000 - tn: 8726.0000 - fn: 1222.0000 - accuracy: 0.8419 - precision: 0.6406 - recall: 0.4773 - auc: 0.8784 - val_loss: 1.0121 - val_tp: 267.0000 - val_fp: 187.0000 - val_tn: 2153.0000 - val_fn: 318.0000 - val_accuracy: 0.8274 - val_precision: 0.5881 - val_recall: 0.4564 - val_auc: 0.8638\n",
            "Epoch 29/150\n",
            "228/234 [============================>.] - ETA: 0s - loss: 0.9626 - tp: 1123.0000 - fp: 647.0000 - tn: 8473.0000 - fn: 1157.0000 - accuracy: 0.8418 - precision: 0.6345 - recall: 0.4925 - auc: 0.8781Restoring model weights from the end of the best epoch.\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.9646 - tp: 1148.0000 - fp: 662.0000 - tn: 8690.0000 - fn: 1190.0000 - accuracy: 0.8416 - precision: 0.6343 - recall: 0.4910 - auc: 0.8776 - val_loss: 1.0271 - val_tp: 260.0000 - val_fp: 176.0000 - val_tn: 2164.0000 - val_fn: 325.0000 - val_accuracy: 0.8287 - val_precision: 0.5963 - val_recall: 0.4444 - val_auc: 0.8611\n",
            "Epoch 00029: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRfn6vcDUZRi"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxS0eMYUZsFi"
      },
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "all_train_df = weather.drop(drop_list,axis = 1 )\n",
        "all_train_df.head()\n",
        "# Form np arrays of labels and features.\n",
        "all_train_labels = np.array(all_train_df.pop('Y'))\n",
        "all_bool_train_labels = all_train_labels != 0\n",
        "\n",
        "all_train_features = np.array(all_train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHJ67UwaZzRF",
        "outputId": "905c2581-85c7-402f-af66-8ab214f48780"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "all_train_features = scaler.fit_transform(all_train_features)\n",
        "\n",
        "all_train_features = np.clip(all_train_features, -5, 5)\n",
        "\n",
        "all_train_labels = pd.get_dummies(all_train_labels,sparse=True)\n",
        "\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Training features shape:', train_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training labels shape: (2338, 5)\n",
            "Training features shape: (2338, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "SiaE1FfMU3eG",
        "outputId": "12f8cc91-b9b3-497a-c1ee-1a62c7b9c2c5"
      },
      "source": [
        "all_train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3649</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3651</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3652</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3653</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3654 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1  2  3  4  5\n",
              "0     0  0  1  0  0\n",
              "1     0  0  0  0  1\n",
              "2     0  0  1  0  0\n",
              "3     0  1  0  0  0\n",
              "4     0  1  0  0  0\n",
              "...  .. .. .. .. ..\n",
              "3649  0  1  0  0  0\n",
              "3650  0  1  0  0  0\n",
              "3651  0  0  1  0  0\n",
              "3652  0  1  0  0  0\n",
              "3653  0  0  0  1  0\n",
              "\n",
              "[3654 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weXHAvZHNS3J",
        "outputId": "caba5573-a3a1-40b7-e7d1-eb7c9d9e2c9d"
      },
      "source": [
        "model.fit(\n",
        "    all_train_features,\n",
        "    all_train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "366/366 [==============================] - 2s 5ms/step - loss: 0.6844 - tp: 2621.0000 - fp: 818.0000 - tn: 13798.0000 - fn: 1033.0000 - accuracy: 0.8987 - precision: 0.7621 - recall: 0.7173 - auc: 0.9391 - val_loss: 0.5388 - val_tp: 465.0000 - val_fp: 83.0000 - val_tn: 2257.0000 - val_fn: 120.0000 - val_accuracy: 0.9306 - val_precision: 0.8485 - val_recall: 0.7949 - val_auc: 0.9658\n",
            "Epoch 2/150\n",
            "366/366 [==============================] - 2s 6ms/step - loss: 0.6459 - tp: 2674.0000 - fp: 793.0000 - tn: 13823.0000 - fn: 980.0000 - accuracy: 0.9030 - precision: 0.7713 - recall: 0.7318 - auc: 0.9451 - val_loss: 0.5469 - val_tp: 462.0000 - val_fp: 88.0000 - val_tn: 2252.0000 - val_fn: 123.0000 - val_accuracy: 0.9279 - val_precision: 0.8400 - val_recall: 0.7897 - val_auc: 0.9637\n",
            "Epoch 3/150\n",
            "366/366 [==============================] - 2s 5ms/step - loss: 0.6836 - tp: 2715.0000 - fp: 762.0000 - tn: 13854.0000 - fn: 939.0000 - accuracy: 0.9069 - precision: 0.7808 - recall: 0.7430 - auc: 0.9411 - val_loss: 0.5549 - val_tp: 453.0000 - val_fp: 85.0000 - val_tn: 2255.0000 - val_fn: 132.0000 - val_accuracy: 0.9258 - val_precision: 0.8420 - val_recall: 0.7744 - val_auc: 0.9626\n",
            "Epoch 4/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6774 - tp: 2710.0000 - fp: 786.0000 - tn: 13830.0000 - fn: 944.0000 - accuracy: 0.9053 - precision: 0.7752 - recall: 0.7417 - auc: 0.9403 - val_loss: 0.5331 - val_tp: 461.0000 - val_fp: 69.0000 - val_tn: 2271.0000 - val_fn: 124.0000 - val_accuracy: 0.9340 - val_precision: 0.8698 - val_recall: 0.7880 - val_auc: 0.9666\n",
            "Epoch 5/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6696 - tp: 2677.0000 - fp: 799.0000 - tn: 13817.0000 - fn: 977.0000 - accuracy: 0.9028 - precision: 0.7701 - recall: 0.7326 - auc: 0.9409 - val_loss: 0.5320 - val_tp: 468.0000 - val_fp: 71.0000 - val_tn: 2269.0000 - val_fn: 117.0000 - val_accuracy: 0.9357 - val_precision: 0.8683 - val_recall: 0.8000 - val_auc: 0.9672\n",
            "Epoch 6/150\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.6691 - tp: 2674.0000 - fp: 786.0000 - tn: 13830.0000 - fn: 980.0000 - accuracy: 0.9033 - precision: 0.7728 - recall: 0.7318 - auc: 0.9422 - val_loss: 0.5160 - val_tp: 468.0000 - val_fp: 72.0000 - val_tn: 2268.0000 - val_fn: 117.0000 - val_accuracy: 0.9354 - val_precision: 0.8667 - val_recall: 0.8000 - val_auc: 0.9686\n",
            "Epoch 7/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6585 - tp: 2691.0000 - fp: 774.0000 - tn: 13842.0000 - fn: 963.0000 - accuracy: 0.9049 - precision: 0.7766 - recall: 0.7365 - auc: 0.9430 - val_loss: 0.5094 - val_tp: 469.0000 - val_fp: 75.0000 - val_tn: 2265.0000 - val_fn: 116.0000 - val_accuracy: 0.9347 - val_precision: 0.8621 - val_recall: 0.8017 - val_auc: 0.9700\n",
            "Epoch 8/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6940 - tp: 2616.0000 - fp: 812.0000 - tn: 13804.0000 - fn: 1038.0000 - accuracy: 0.8987 - precision: 0.7631 - recall: 0.7159 - auc: 0.9367 - val_loss: 0.5476 - val_tp: 458.0000 - val_fp: 79.0000 - val_tn: 2261.0000 - val_fn: 127.0000 - val_accuracy: 0.9296 - val_precision: 0.8529 - val_recall: 0.7829 - val_auc: 0.9659\n",
            "Epoch 9/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6804 - tp: 2597.0000 - fp: 791.0000 - tn: 13825.0000 - fn: 1057.0000 - accuracy: 0.8989 - precision: 0.7665 - recall: 0.7107 - auc: 0.9399 - val_loss: 0.5113 - val_tp: 463.0000 - val_fp: 63.0000 - val_tn: 2277.0000 - val_fn: 122.0000 - val_accuracy: 0.9368 - val_precision: 0.8802 - val_recall: 0.7915 - val_auc: 0.9688\n",
            "Epoch 10/150\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 0.6893 - tp: 2645.0000 - fp: 824.0000 - tn: 13792.0000 - fn: 1009.0000 - accuracy: 0.8997 - precision: 0.7625 - recall: 0.7239 - auc: 0.9383 - val_loss: 0.5251 - val_tp: 480.0000 - val_fp: 74.0000 - val_tn: 2266.0000 - val_fn: 105.0000 - val_accuracy: 0.9388 - val_precision: 0.8664 - val_recall: 0.8205 - val_auc: 0.9676\n",
            "Epoch 11/150\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 0.7066 - tp: 2610.0000 - fp: 829.0000 - tn: 13787.0000 - fn: 1044.0000 - accuracy: 0.8975 - precision: 0.7589 - recall: 0.7143 - auc: 0.9381 - val_loss: 0.5570 - val_tp: 459.0000 - val_fp: 78.0000 - val_tn: 2262.0000 - val_fn: 126.0000 - val_accuracy: 0.9303 - val_precision: 0.8547 - val_recall: 0.7846 - val_auc: 0.9636\n",
            "Epoch 12/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6514 - tp: 2667.0000 - fp: 803.0000 - tn: 13813.0000 - fn: 987.0000 - accuracy: 0.9020 - precision: 0.7686 - recall: 0.7299 - auc: 0.9441 - val_loss: 0.4942 - val_tp: 476.0000 - val_fp: 72.0000 - val_tn: 2268.0000 - val_fn: 109.0000 - val_accuracy: 0.9381 - val_precision: 0.8686 - val_recall: 0.8137 - val_auc: 0.9714\n",
            "Epoch 13/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6528 - tp: 2694.0000 - fp: 783.0000 - tn: 13833.0000 - fn: 960.0000 - accuracy: 0.9046 - precision: 0.7748 - recall: 0.7373 - auc: 0.9442 - val_loss: 0.5071 - val_tp: 473.0000 - val_fp: 75.0000 - val_tn: 2265.0000 - val_fn: 112.0000 - val_accuracy: 0.9361 - val_precision: 0.8631 - val_recall: 0.8085 - val_auc: 0.9693\n",
            "Epoch 14/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6760 - tp: 2636.0000 - fp: 826.0000 - tn: 13790.0000 - fn: 1018.0000 - accuracy: 0.8991 - precision: 0.7614 - recall: 0.7214 - auc: 0.9399 - val_loss: 0.5196 - val_tp: 473.0000 - val_fp: 71.0000 - val_tn: 2269.0000 - val_fn: 112.0000 - val_accuracy: 0.9374 - val_precision: 0.8695 - val_recall: 0.8085 - val_auc: 0.9669\n",
            "Epoch 15/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6584 - tp: 2687.0000 - fp: 793.0000 - tn: 13823.0000 - fn: 967.0000 - accuracy: 0.9037 - precision: 0.7721 - recall: 0.7354 - auc: 0.9432 - val_loss: 0.5131 - val_tp: 479.0000 - val_fp: 73.0000 - val_tn: 2267.0000 - val_fn: 106.0000 - val_accuracy: 0.9388 - val_precision: 0.8678 - val_recall: 0.8188 - val_auc: 0.9672\n",
            "Epoch 16/150\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.6960 - tp: 2646.0000 - fp: 804.0000 - tn: 13812.0000 - fn: 1008.0000 - accuracy: 0.9008 - precision: 0.7670 - recall: 0.7241 - auc: 0.9395 - val_loss: 0.5367 - val_tp: 467.0000 - val_fp: 76.0000 - val_tn: 2264.0000 - val_fn: 118.0000 - val_accuracy: 0.9337 - val_precision: 0.8600 - val_recall: 0.7983 - val_auc: 0.9653\n",
            "Epoch 17/150\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.6517 - tp: 2714.0000 - fp: 772.0000 - tn: 13844.0000 - fn: 940.0000 - accuracy: 0.9063 - precision: 0.7785 - recall: 0.7427 - auc: 0.9439 - val_loss: 0.5132 - val_tp: 463.0000 - val_fp: 77.0000 - val_tn: 2263.0000 - val_fn: 122.0000 - val_accuracy: 0.9320 - val_precision: 0.8574 - val_recall: 0.7915 - val_auc: 0.9673\n",
            "Epoch 18/150\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.6722 - tp: 2666.0000 - fp: 798.0000 - tn: 13818.0000 - fn: 988.0000 - accuracy: 0.9022 - precision: 0.7696 - recall: 0.7296 - auc: 0.9405 - val_loss: 0.5486 - val_tp: 458.0000 - val_fp: 79.0000 - val_tn: 2261.0000 - val_fn: 127.0000 - val_accuracy: 0.9296 - val_precision: 0.8529 - val_recall: 0.7829 - val_auc: 0.9647\n",
            "Epoch 19/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6506 - tp: 2710.0000 - fp: 785.0000 - tn: 13831.0000 - fn: 944.0000 - accuracy: 0.9054 - precision: 0.7754 - recall: 0.7417 - auc: 0.9441 - val_loss: 0.5401 - val_tp: 466.0000 - val_fp: 91.0000 - val_tn: 2249.0000 - val_fn: 119.0000 - val_accuracy: 0.9282 - val_precision: 0.8366 - val_recall: 0.7966 - val_auc: 0.9634\n",
            "Epoch 20/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6809 - tp: 2636.0000 - fp: 819.0000 - tn: 13797.0000 - fn: 1018.0000 - accuracy: 0.8995 - precision: 0.7630 - recall: 0.7214 - auc: 0.9400 - val_loss: 0.5139 - val_tp: 475.0000 - val_fp: 80.0000 - val_tn: 2260.0000 - val_fn: 110.0000 - val_accuracy: 0.9350 - val_precision: 0.8559 - val_recall: 0.8120 - val_auc: 0.9682\n",
            "Epoch 21/150\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.7137 - tp: 2676.0000 - fp: 786.0000 - tn: 13830.0000 - fn: 978.0000 - accuracy: 0.9034 - precision: 0.7730 - recall: 0.7323 - auc: 0.9404 - val_loss: 0.5163 - val_tp: 475.0000 - val_fp: 71.0000 - val_tn: 2269.0000 - val_fn: 110.0000 - val_accuracy: 0.9381 - val_precision: 0.8700 - val_recall: 0.8120 - val_auc: 0.9667\n",
            "Epoch 22/150\n",
            "357/366 [============================>.] - ETA: 0s - loss: 0.6776 - tp: 2605.0000 - fp: 806.0000 - tn: 13474.0000 - fn: 965.0000 - accuracy: 0.9008 - precision: 0.7637 - recall: 0.7297 - auc: 0.9402Restoring model weights from the end of the best epoch.\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.6791 - tp: 2664.0000 - fp: 827.0000 - tn: 13789.0000 - fn: 990.0000 - accuracy: 0.9005 - precision: 0.7631 - recall: 0.7291 - auc: 0.9399 - val_loss: 0.5270 - val_tp: 465.0000 - val_fp: 82.0000 - val_tn: 2258.0000 - val_fn: 120.0000 - val_accuracy: 0.9309 - val_precision: 0.8501 - val_recall: 0.7949 - val_auc: 0.9650\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4400d99ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 485
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "9hOInVONUWe1",
        "outputId": "0ce94d9a-6a42-40fc-e8d2-148fe936325c"
      },
      "source": [
        "test_data = pd.read_csv(\"test.csv\")\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.26</td>\n",
              "      <td>12.4</td>\n",
              "      <td>0.048</td>\n",
              "      <td>50.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>0.99720</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.38</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0.044</td>\n",
              "      <td>35.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>0.99326</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>8.1</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.049</td>\n",
              "      <td>50.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.99710</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.57</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.037</td>\n",
              "      <td>37.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.99006</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.68</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.30</td>\n",
              "      <td>12.9</td>\n",
              "      <td>0.033</td>\n",
              "      <td>31.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>0.99479</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.39</td>\n",
              "      <td>11.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   X1    X2    X3    X4  ...     X7       X8    X9   X10   X11\n",
              "0           0  6.0  0.19  0.26  12.4  ...  147.0  0.99720  3.30  0.36   8.9\n",
              "1           1  6.4  0.22  0.38   9.1  ...  127.0  0.99326  2.97  0.30  11.0\n",
              "2           2  8.1  0.30  0.49  12.3  ...  144.0  0.99710  3.09  0.57  10.2\n",
              "3           3  6.6  0.19  0.35   1.5  ...  107.0  0.99006  3.18  0.68  12.0\n",
              "4           4  6.6  0.28  0.30  12.9  ...  177.0  0.99479  3.12  0.39  11.2\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "-BAd81BOUWzm",
        "outputId": "28c4ade4-6153-45eb-915b-4bbf776af1e8"
      },
      "source": [
        "drop_list2 = ['Unnamed: 0']\n",
        "test_data_X = test_data.drop(drop_list2,axis = 1 )\n",
        "test_data_X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.26</td>\n",
              "      <td>12.4</td>\n",
              "      <td>0.048</td>\n",
              "      <td>50.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>0.99720</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.38</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0.044</td>\n",
              "      <td>35.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>0.99326</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.049</td>\n",
              "      <td>50.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.99710</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.57</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.037</td>\n",
              "      <td>37.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.99006</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.68</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.30</td>\n",
              "      <td>12.9</td>\n",
              "      <td>0.033</td>\n",
              "      <td>31.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>0.99479</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.39</td>\n",
              "      <td>11.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    X1    X2    X3    X4     X5    X6     X7       X8    X9   X10   X11\n",
              "0  6.0  0.19  0.26  12.4  0.048  50.0  147.0  0.99720  3.30  0.36   8.9\n",
              "1  6.4  0.22  0.38   9.1  0.044  35.0  127.0  0.99326  2.97  0.30  11.0\n",
              "2  8.1  0.30  0.49  12.3  0.049  50.0  144.0  0.99710  3.09  0.57  10.2\n",
              "3  6.6  0.19  0.35   1.5  0.037  37.0  107.0  0.99006  3.18  0.68  12.0\n",
              "4  6.6  0.28  0.30  12.9  0.033  31.0  177.0  0.99479  3.12  0.39  11.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdZW_3VpTgOa"
      },
      "source": [
        "test_train_features = np.array(test_data_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3CrDcpAT91H",
        "outputId": "0c977a2d-4c94-4d82-df26-f996509ce6b2"
      },
      "source": [
        "test_train_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.  ,  0.19,  0.26, ...,  3.3 ,  0.36,  8.9 ],\n",
              "       [ 6.4 ,  0.22,  0.38, ...,  2.97,  0.3 , 11.  ],\n",
              "       [ 8.1 ,  0.3 ,  0.49, ...,  3.09,  0.57, 10.2 ],\n",
              "       ...,\n",
              "       [ 7.3 ,  0.29,  0.37, ...,  3.12,  0.47,  9.  ],\n",
              "       [ 7.6 ,  0.22,  0.34, ...,  3.08,  0.49,  9.8 ],\n",
              "       [ 6.8 ,  0.21,  0.36, ...,  3.27,  0.48,  8.8 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCDQXCMIUKu-",
        "outputId": "064eef15-fe1b-4d91-dfad-38d271e32220"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "# test_train_features = scaler.fit_transform(test_train_features)\n",
        "\n",
        "test_train_features = np.clip(test_train_features, -5, 5)\n",
        "\n",
        "print('Training features shape:', train_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training features shape: (2338, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv3ZUou7UVNL",
        "outputId": "93725507-f3b8-40ce-f6f3-f504b33f1710"
      },
      "source": [
        "test_train_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.  , 0.19, 0.26, ..., 3.3 , 0.36, 5.  ],\n",
              "       [5.  , 0.22, 0.38, ..., 2.97, 0.3 , 5.  ],\n",
              "       [5.  , 0.3 , 0.49, ..., 3.09, 0.57, 5.  ],\n",
              "       ...,\n",
              "       [5.  , 0.29, 0.37, ..., 3.12, 0.47, 5.  ],\n",
              "       [5.  , 0.22, 0.34, ..., 3.08, 0.49, 5.  ],\n",
              "       [5.  , 0.21, 0.36, ..., 3.27, 0.48, 5.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 491
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQZA5INTTBrd",
        "outputId": "c3bda634-869c-4174-d915-c7ff611db656"
      },
      "source": [
        "Y_predict = model.predict_classes(test_train_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f44143d9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9b0wifXWZsY",
        "outputId": "ac35f55f-b7f2-42ab-bc89-b791faff0fa1"
      },
      "source": [
        "Y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq_W2o3Wekl_"
      },
      "source": [
        "Y_predict+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSscpuDAfJCW",
        "outputId": "8afa4dd2-d793-4c18-944f-4060ed03cf5f"
      },
      "source": [
        "Y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, ..., 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IScCSmGiUuxM"
      },
      "source": [
        "predict_sample = pd.read_csv(\"sample_submission.csv\", index_col=0)\n",
        "predict_sample['Y'] = Y_predict\n",
        "predict_sample.to_csv(\"predict_6.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HC49BBgQvZs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}